\chapter*{Future Work}
\addcontentsline{toc}{part}{Future Work}

Although the theory section and the implementation of algorithms give a solid basis to achieve the goal of the system and the experiments are promising, there is still work to do.

The first step would be carrying out the different experiments once again but with adapted tools in order to obtain a precise calibration. Moreover, the color detection algorithm could be improved in order to detect the same pixels over time. Once these two improvements done, it would be interesting to compute the new errors of the experiments to check whether or not they decrease a lot as expected and if these errors are small enough to achieve an accurate determination of the distance board-target. It would also be appreciable to carry out integration tests with the conceived artificial light source and the camera. Indeed, even if the Signal/Noise ratio calculated validates their design, tests have to be performed. For instance, it could permit to verify the depth of field, the SNR and if the camera works well with a target between one and two meters. It could also allow to implement an algorithm to adjust the shutter time linked with the luminosity of the scene over time. Then, as the algorithms work with a line of lighting dots, it should also be efficient with a grid, and thus an experiment should be executed. Finally, an integration test should be carried out on the whole system, that is to say the camera, the artificial light source plus the algorithms.

Moreover, the use of patterns could be considered instead of a grid of dots. Indeed, the projection of a pattern could permit a more detailed 3D map. We could also manipulate a grid with more points into the same surface but a lot of pattern disorders would appear into the projected grid whereas patterns such as the ones described in the Theory Section permit to detect and correct these disorders.

Also, even if the system works well, we have to be sure that it will still be the case on Mars. To do so, it would be interesting to effectuate some researches on the resistance of the components. Indeed, as we said into the section \ref{climate}, there are extreme variations in temperatures, large storms, wind and dust. Thus, the climate and the dust can damage the components or decrease their performance or even lead to malfunctions. For instance the lens of the camera striped by the dust would cause an erroneous detection of the lighting dots. Moreover, the calibration (namely the angles between the focal axis of the camera and the beams of the artificial light source) will probably change because of the vibrations during the take-off and landing of the spacecraft. Thus, a method to allow the rover to calibrate the system itself should be studied.

Once the determination of the distances camera-target will give precise results, two algorithms will need to be implemented. The first one will compute the translations and rotations between two successive 3D maps and the second one will use these results to find the parameters needed to stabilize the camera of the rover.

Finally, we need to embed the system. The mechanical and electronic issues will need to be solved. For example, the different algorithms must be embedded on processor(s). In order to choose the CPU, the issues of the computation power (the processor needs to be powerful enough to have quick run time to work in real time) and the power consumption (there is a limited power available) will need to be balanced to find an efficient compromise. Also, as the artificial light source will probably not be on board at the same level as the camera, different distances \emph{d} will have to be measured during the calibration. Indeed, as the artificial light source will probably be behind the camera, the distances \emph{d} must be measured between the camera and each beam of the light source.