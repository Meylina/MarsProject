\section*{Future Work}
\addcontentsline{toc}{part}{Future Work}

Even if the theory section and the implementation of algorithms give a solid basis to achieve the goal of the system and the experiments give good prospects, there is still work to do.

The first step would be carrying out the different experiments once again but with adapted tools in order to obtain a precise calibration. Moreover, the color detection algorithm could be improved in order to detect the same pixels over time. Once these two improvements done, it would be interesting to compute the new errors of the experiments to check weather or not they decrease a lot as expected and if these errors are small enough to achieve a precise determination of the distance board-target. It would also be great to carry out integration tests on the artificial light source and the camera. Indeed, even if the Signal/Noise ratio calculated validates its design, tests have to be performed. As instance it could permit to verify the depth of field, the SNR and if the camera works well with a target between one and two meters. It could also permit to implement an algorithm to adjust the shutter time in line with the luminosity of the scene over time. Then, as the algorithms should work with a grid of lighting dots instead of a line of dots but have not been tested, an experiment should be performed. Finally, an integration test should be carried out on the whole system, that is to say the camera plus the artificial light source plus the algorithms.

Moreover, the use of patterns could be considered instead of a gird of dots. Indeed, the projection of a pattern could permit a more detailed 3D map. A grid with more dots into the same surface could also be used but a lot of patterns disorders would appear into into the projected grid whereas the pattern permits to detect and correct these disorders.

Also, even the system works well, we have to be sure that it still works on Mars. To do so, it would be great to do some researches on the resistance of the components. Indeed, as we said into the section \ref{climate}, there are extreme variations in temperatures, large storms, wind and dust. Thus, the climate and the dust can damage the components or decrease their performance or even if lead to malfunctions. As instance a camera's lens striped by the dust would lead to a erroneous detection of the lighting dots. Moreover, the calibration (as instance the angles between the focal axis of the camera and the beams of the artificial light source) will probably change because of the vibrations during the take-off and landing of the spacecraft. Thus, a method to permit the rover to calibrate the system itself should be studied.

Once the determination of the distances camera-target will give precise results, two algorithms will need to be implemented. The first one will compute the translations and rotations between two successive 3D maps and the second one will use these results to find the parameters needed to stabilize the camera of the rover.

Finally, we need to embed the system. the mechanical and electronic issues will need to be solved. As instance, the different algorithms need to be embedded on processor(s). In order to choose the processor, the issues of the computation power (the processor needs to be powerful enough to have quick run time to work in real time) and the power consumption (there is a limited power available) will need to be balanced to find an efficient compromise. Also, as the artificial light source will probably not be embedded at the same level as that of the camera, different distances \emph{d} will be measured during the calibration. Indeed, as the artificial light source will probably be behind the camera, the distances \emph{d} will be measured between the camera and each beam of the light source.









