\chapter*{Conclusion}
\addcontentsline{toc}{part}{Conclusion}

We designed a system permitting the 3D analysis of a Martian rock using structured light and triangulation theory, and started the implementation by carrying out a color detection of the green dots and a calibration to compute in real time the distances camera-target.

Regarding the camera features, the system allows to work on a target between one and two meters from the rover as expected. Moreover, the depth of field is also satisfied as it is 66.5 cm and the target has a relief of 50 cm maximum. The camera characteristics could even be changed in order to reduce a bit the depth of field and increase other properties, for instance the distance camera-target. Indeed, even if this condition is fulfilled, a bigger distance would permit an easier positioning of the rover. Altough the camera has not been tested, the comparison of its properties with the Navcam and Pancam suggests that it is well designed.

Considering the artificial light source, it has not been checked either but the high Signal/Noise ratio indicates that the lighting points of the grid projected on the target will be bright enough to outshine the natural light and permit to have good images and a well working structured light algorithm.

The robustness of the color detection was evaluated through different indoor and outdoor experiments. The algorithm is found to be efficient to isolate the green beam spots, but needs to be improved for carrying out a better centroiding, which for now causes too high errors. In the first experiment, it was noticed that the distance error was increasing when the object was moved away from the calibration position. In order to reduce this error, the lens distortion was taken into account thanks to the Matlab Calibration Toolbox. As the results were slightly better, it could be concluded they do not need to be considered. However, the last value, far from the reference, is confusing and the distortion needs to be corrected. Then, even if the results of the experiment with the line of dots show that the algorithm is robust but would not be rigorous enough to obtain a precise 3D map of the target, it give us good prospects. Indeed, the poor calibration suggests that the algorithm could be much more errorless with an accurate calibration carried out with adapted tools which we did not have. 

As regards the real time, as the system has to rectify the position of the rover's arm in order to keep the camera focused on the target, the algorithm needs to be fast enough to send as quickly as possible the data needed for the revision of the position. This goal is also met as the algorithms work in real time and permit to receive the different distances continuously.

Finally, we manage to design an embedded system gathering a camera, an artificial light source and algorithms, which seems able to carry out a partial 3D map of a Martian rocks in real time, relevant for stabilizing the robot arm.